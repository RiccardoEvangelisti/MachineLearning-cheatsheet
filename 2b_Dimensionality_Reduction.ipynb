{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curse of Dimensionality \n",
    "It refers to the problems associated with multivariate data analysis: for a given sample size, there is a maximum number of features above which the performance of the model will degrade rather than improve.\n",
    "- Increased Computation: More dimensions require additional computational resources and time to process the data.\n",
    "- Overfitting: Models can become overly complex, fitting to noise rather than the underlying pattern, reducing their ability to generalize.\n",
    "- Loss of Distance Meaning: In high dimensions, the difference in distances between data points tends to become negligible, affecting measures like Euclidean distance.\n",
    "- In most cases, the extra information that is lost by discarding certain features is compensated by a more accurate mapping into the smaller dimensional space. Solutions: \n",
    "    - Add a priori knowledge to weigh more some variables instead of others; \n",
    "    - Reduce dimensionality by using (un)supervised algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"datasets/winequality-red.csv\", sep=\";\")\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]  # last column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA)\n",
    "- https://www.youtube.com/watch?v=FD4DeN81ODY\n",
    "- PCA it's an unsupervised method that uses an orthogonal transformation to convert a set of correlated variables into a set of uncorrelated variables.\n",
    "\n",
    "- The primary goal of PCA is to reduce the dimensionality of a dataset while preserving the most important patterns or relationships between the variables, without any prior knowledge of the target variables. In fact, it does not consider the class labels of the samples (\"class separability\")\n",
    "\n",
    "- PCA identifies a set of orthogonal axes (eigenvectors) that capture the maximum variance in the data. This process involves the following steps:\n",
    "    1. **Standardization**: Each column (feature) of the dataset is standardized to have a mean of 0 and a standard deviation of 1. If one feature varies more than the others only because of their respective scales, PCA would determine that such feature dominates the direction of the principal components.\n",
    "    2. **Covariance Matrix Calculation**: The covariance matrix of the standardized data is calculated.\n",
    "    3. **Eigenvalues and Eigenvectors Calculation**: The eigenvalues and eigenvectors of the covariance matrix are calculated. The eigenvectors (which represent the directions in which the data vary the most) become the axes of the new space, while the eigenvalues (which indicate the amount of variance along each axis) determine the importance of each eigenvector. The eigenvectors are orthogonal to each other. A higher eigenvalue means that its eigenvector follows data that vary a lot.\n",
    "    \n",
    "        ![image.png](attachment:image.png) Here the best eigenvector is the one that follows the data points.\n",
    "    \n",
    "    4. **Principal Component Features Derivation**: The Principal Component features are derived by taking the dot product of the eigenvectors and the standardized columns. This projects the dataset into a new space with reduced dimensionality. Excluding the \"non-significant\" principal components may filter out the noise that is present in the data.\n",
    "\n",
    "- The maximum number of PCs that can be calculated is min(n_samples, n_features)\n",
    "- The number of PCs to keep is the one that preserves at least 95% of the total variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.48561286e-01 4.64263108e-02 2.51642763e-03 1.56686004e-03\n",
      " 8.54121349e-04 3.59942769e-05 1.97718297e-05 9.54972714e-06\n",
      " 8.45436759e-06 1.22342746e-06]\n",
      "Sum: 0.9999999995231198\n"
     ]
    }
   ],
   "source": [
    "# n_components is how many PCs to keep\n",
    "pca = PCA(random_state=42, n_components=\"mle\")\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_t = pca.transform(X_train)\n",
    "X_test_t = pca.transform(X_test)\n",
    "\n",
    "# Percentage of variance explained by each of the selected components\n",
    "# The sum needs to be at least 95%, otherwise too much information is lost\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(\"Sum:\", pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94856129 0.9949876  0.99750402 0.99907088 0.99992501 0.999961\n",
      " 0.99998077 0.99999032 0.99999878 1.        ]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Sort the explained variance ratios in descending order\n",
    "ratios = np.flip(np.sort(pca.explained_variance_ratio_))\n",
    "\n",
    "# Calculate the cumulative sum of the explained variance ratios\n",
    "cum_sum = np.cumsum(ratios)\n",
    "\n",
    "print(cum_sum)\n",
    "\n",
    "# Find the index i of the first principal component where the cumulative sum exceeds 0.999\n",
    "i = np.argmax(cum_sum > 0.999)\n",
    "print(i)\n",
    "\n",
    "# Keep the first i principal components and discard the rest\n",
    "X_train_t = X_train_t[:, :i]\n",
    "X_test_t = X_test_t[:, :i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: original: 0.5625\n",
      "Classification Accuracy: transformed by PCA: 0.49583333333333335\n",
      "Classification Accuracy: transformed by PCA, selecting only most valuable variable: 0.4791666666666667\n"
     ]
    }
   ],
   "source": [
    "# Classification with original data\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=42, max_iter=300)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Classification Accuracy: original:\", clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# Classification with PCA data transformed\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=42, max_iter=300)\n",
    "clf.fit(X_train_t, y_train)\n",
    "print(\"Classification Accuracy: transformed by PCA:\", clf.score(X_test_t, y_test))\n",
    "\n",
    "# Classification with PCA data transformed and selecting ONLY the most valuable attribute (the first)\n",
    "col = 0\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=42, max_iter=300)\n",
    "X_train_t_head = X_train_t[:, col].reshape(-1, 1)\n",
    "X_test_t_head = X_test_t[:, col].reshape(-1, 1)\n",
    "clf.fit(X_train_t_head, y_train)\n",
    "print(\n",
    "    \"Classification Accuracy: transformed by PCA, selecting only most valuable variable:\",\n",
    "    clf.score(X_test_t_head, y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Linear Discriminant Analysis (LDA)\n",
    "- LDA is a supervised learning algorithm that works by projecting the data onto a lower-dimensional space that maximizes the separation between the classes. It can also be used to predict, finding a linear combination of features that best separates the classes in a dataset.\n",
    "\n",
    "- It does this by finding a set of linear discriminants that maximize the ratio of between-class variance to within-class variance. In other words, it finds the directions in the feature space that best separates the different classes of data. \n",
    "\n",
    "- LDA assumes that the data has a Gaussian distribution and that the covariance matrices of the different classes are equal. It also assumes that the data is linearly separable, meaning that a linear decision boundary can accurately classify the different classes. In fact, often it's used to understand if a linear model can be used.\n",
    "\n",
    "    1. **Compute the mean vectors**: For each class in the dataset, calculate the mean vector. Each element of the mean vector is the average of one feature for that class (therefore its width it's the number of dataset features)\n",
    "    2. **Compute the scatter matrices**: Calculate the *within-class* ($S_W$) and *in-between-class* ($S_B$) scatter matrices (\"intra-class\" and \"inter-class\" matrices). The first captures the information about the spread of the data within each class. The second gathers information about how classes are spread between themselves.\n",
    "    3. **Calculate the projection matrix**: Find a matrix, called the Projection matrix, that, multiplied by the original dataset, gives as a result a new space such that the class separability is maximized. It means maximizing the *in-between-class* scatter matrix while minimizing the *within-class* matrix. The columns of the Projection matrix are the $C-1$ largest eigenvectors of the matrix $J = S_W^{-1} S_B$\n",
    "    5. **Transform the dataset**: Project the original dataset onto this new subspace, taking the dot product of the Projection matrix and the standardized columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(solver=\"eigen\")\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "X_train_t = lda.transform(X_train)\n",
    "X_test_t = lda.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy: original: 0.5625\n",
      "Classification Accuracy: transformed by LDA: 0.5583333333333333\n",
      "Classification Accuracy: transformed by LDA, selecting only most valuable variable: 0.40625\n"
     ]
    }
   ],
   "source": [
    "# Classification with original data\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=42, max_iter=200)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Classification Accuracy: original:\", clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# Classification with data transformed with LDA\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=42, max_iter=200)\n",
    "clf.fit(X_train_t, y_train)\n",
    "print(\"Classification Accuracy: transformed by LDA:\", clf.score(X_test_t, y_test))\n",
    "\n",
    "# Classification with data transformed with LDA and selecting ONLY the most valuable attribute (the first)\n",
    "col = 0\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=42, max_iter=200)\n",
    "X_train_t_head = X_train_t[:, col].reshape(-1, 1)\n",
    "X_test_t_head = X_test_t[:, col].reshape(-1, 1)\n",
    "clf.fit(X_train_t_head, y_train)\n",
    "print(\n",
    "    \"Classification Accuracy: transformed by LDA, selecting only most valuable variable:\",\n",
    "    clf.score(X_test_t_head, y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "- It's a technique for dimensionality reduction that is particularly well-suited for the visualization of high-dimensional datasets\n",
    "- More info:\n",
    "• https://lvdmaaten.github.io/tsne/\n",
    "• https://distill.pub/2016/misread-tsne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### SelectKBest\n",
    "- A type of Univariate Feature Selection [(doc)](https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection)\n",
    "- Selects the best features based on univariate statistical tests.\n",
    "- These objects take as input a scoring function that returns univariate scores and p-values:\n",
    "    - For regression: r_regression, f_regression, mutual_info_regression\n",
    "    - For classification: chi2, f_classif, mutual_info_classif\n",
    "- The methods based on F-test estimate the degree of linear dependency between two random variables. On the other hand, mutual information methods can capture any kind of statistical dependency, but being nonparametric, they require more samples for accurate estimation. Note that the chi2 test should only be applied to non-negative features, such as frequencies.\n",
    "- If you use sparse data (i.e. data represented as sparse matrices), chi2, mutual_info_regression, mutual_info_classif will deal with the data without making it dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = SelectKBest(f_classif, k=2).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
