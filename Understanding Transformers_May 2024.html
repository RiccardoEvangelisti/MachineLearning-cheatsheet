<html lang=en><head>
        <meta charset=utf-8>
        <meta name=viewport content="width=device-width, initial-scale=1.0">
        <meta http-equiv=X-UA-Compatible content="ie=edge">
        <title>Understanding Transformers | by Frederik vom Lehn | in Advanced Deep Learning - Freedium</title>
        
        <meta name=description content="The underlying deep learning architecture for ChatGPT and new vision models.">
        <meta name=keywords content="medium, paywall, medium.com, paywall breakthrough">
        <script src="https://cdn.tailwindcss.com"></script>
        <script src="https://cdn.tailwindcss.com?plugins=forms,typography,aspect-ratio"></script>
        <link href="https://glyph.medium.com/css/unbound.css" rel=stylesheet>
        <link rel=apple-touch-icon sizes=180x180 href="/apple-touch-icon.png">
        <link rel=icon type="image/png" sizes=32x32 href="/favicon-32x32.png">
        <link rel=icon type="image/png" sizes=16x16 href="/favicon-16x16.png">
        <link rel=manifest href="/site.webmanifest">
        <link rel=mask-icon href="/safari-pinned-tab.svg" color=#00aba9>
        <meta name=msapplication-TileColor content=#00aba9>
        <meta name=theme-color content=#ffffff>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <link rel=stylesheet href="https://unpkg.com/@highlightjs/cdn-assets@11.8.0/styles/atom-one-dark.min.css">
        <script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.4/dist/lazyload.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/lightense-images@1.0.17/dist/lightense.min.js"></script>
        <script>
            if (localStorage.theme === 'dark' || (!('theme' in localStorage) && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
  document.documentElement.classList.add('dark');
  //document.getElementById('darkIcon').classList.remove('hidden');
  //document.getElementById('lightIcon').classList.add('hidden')
} else {
  document.documentElement.classList.remove('dark')
  //document.getElementById('lightIcon').classList.remove('hidden');
  //document.getElementById('darkIcon').classList.add('hidden');
}
        </script>
        <style>
          .overflow-hidden {
              overflow: hidden !important;
          }

        .shadow-lf {
            box-shadow: inset 3px 0 0 0 rgb(209 207 239 / var(--tw-bg-opacity));
        }
        </style>
        <style>
    .notification-container {
      display: none;
      position: fixed;
      top: 20px;
      padding: 2%;
      max-height: 95vh; /* Set a maximum height for the container */
    overflow-y: auto; /* Enable vertical scrolling */
    }

    .notification-card {
      background-color: #fff;
      border: 1px solid #ccc;
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
      padding: 10px 20px;
      border-radius: 5px;
      text-align: center;
    }
        </style>
        <script>
    window._resizeIframe = function (iframeData)
    {
            iframeData.iframe.height = iframeData.height
            _resizeIframeWidth()
    }

    function _resizeIframeWidth(){ var element = document.querySelector(".main-content");
    var width = element.offsetWidth;

    iframes = document.getElementsByTagName("iframe");
    for (var i = 0; i < iframes.length; i++) {
            iframes[i].width = width
    }

    window.onresize = _resizeIframeWidth
 }
        </script>
        <!--
        <script>
                window.onload = function() {
    window.parent.postMessage({
        type: "URL_UPDATE",
        url: window.location.href
    }, "*");
}
</script>
                -->
    </head>
    <body class="dark:bg-gray-800 bg-white"><div class="fixed bottom-4 left-4" style="z-index: 999999;">
        <button id=openProblemModal class="m-1.5 flex items-center bg-red-500 text-white py-2 px-4 rounded-full shadow-lg hover:bg-red-600 focus:outline-none focus:ring-2 focus:ring-blue-500">
            <svg xmlns="http://www.w3.org/2000/svg" height=1em viewBox="0 0 512 512">
                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2023 Fonticons, Inc. --><style>svg{fill:#ffffff}</style>
                <path d="M256 32c14.2 0 27.3 7.5 34.5 19.8l216 368c7.3 12.4 7.3 27.7 .2 40.1S486.3 480 472 480H40c-14.3 0-27.6-7.7-34.7-20.1s-7-27.8 .2-40.1l216-368C228.7 39.5 241.8 32 256 32zm0 128c-13.3 0-24 10.7-24 24V296c0 13.3 10.7 24 24 24s24-10.7 24-24V184c0-13.3-10.7-24-24-24zm32 224a32 32 0 1 0 -64 0 32 32 0 1 0 64 0z"></path>
            </svg>
        </button>
        <button id=darkModeToggle class="m-1.5 flex items-center bg-blue-500 text-white py-2 px-4 rounded-full shadow-lg hover:bg-blue-600 focus:outline-none">
            <svg id=darkIcon xmlns="http://www.w3.org/2000/svg" height=1em viewBox="0 0 384 512">
                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2023 Fonticons, Inc. -->
                <path d="M223.5 32C100 32 0 132.3 0 256S100 480 223.5 480c60.6 0 115.5-24.2 155.8-63.4c5-4.9 6.3-12.5 3.1-18.7s-10.1-9.7-17-8.5c-9.8 1.7-19.8 2.6-30.1 2.6c-96.9 0-175.5-78.8-175.5-176c0-65.8 36-123.1 89.3-153.3c6.1-3.5 9.2-10.5 7.7-17.3s-7.3-11.9-14.3-12.5c-6.3-.5-12.6-.8-19-.8z"></path>
            </svg>
            <!-- SVG icon for light mode (e.g., a sun) -->
            <svg class=hidden id=lightIcon xmlns="http://www.w3.org/2000/svg" height=1em viewBox="0 0 512 512">
                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2023 Fonticons, Inc. -->
                <path d="M361.5 1.2c5 2.1 8.6 6.6 9.6 11.9L391 121l107.9 19.8c5.3 1 9.8 4.6 11.9 9.6s1.5 10.7-1.6 15.2L446.9 256l62.3 90.3c3.1 4.5 3.7 10.2 1.6 15.2s-6.6 8.6-11.9 9.6L391 391 371.1 498.9c-1 5.3-4.6 9.8-9.6 11.9s-10.7 1.5-15.2-1.6L256 446.9l-90.3 62.3c-4.5 3.1-10.2 3.7-15.2 1.6s-8.6-6.6-9.6-11.9L121 391 13.1 371.1c-5.3-1-9.8-4.6-11.9-9.6s-1.5-10.7 1.6-15.2L65.1 256 2.8 165.7c-3.1-4.5-3.7-10.2-1.6-15.2s6.6-8.6 11.9-9.6L121 121 140.9 13.1c1-5.3 4.6-9.8 9.6-11.9s10.7-1.5 15.2 1.6L256 65.1 346.3 2.8c4.5-3.1 10.2-3.7 15.2-1.6zM160 256a96 96 0 1 1 192 0 96 96 0 1 1 -192 0zm224 0a128 128 0 1 0 -256 0 128 128 0 1 0 256 0z"></path>
            </svg>
        </button>
    </div>
    <div class=notification-container style="z-index: 999999;">
        <div class="notification-card dark:bg-gray-800 bg-white">
            <p class="text-2xl pb-5 text-black dark:text-white">Bad news</p>
            <p class="pb-3 text-black dark:text-white">
                We regret to inform you that our account on BuyMeACoffee has been suspended due to a violation of their terms of service. This was an unexpected development, and we are currently addressing the matter with utmost priority.
            <br>
        <br>
        However, our mission at Freedium remains unchanged, and your support is more crucial than ever. We are transitioning to Patreon, a platform that aligns with our values and offers us the freedom to share our work with you.
    <br>
<br>
Please join us on Patreon and continue to support our endeavors. Your contributions are invaluable to us, and we are committed to delivering the quality content youâ€™ve come to expect from Freedium.
<br>
<br>
Thank you for your understanding and unwavering support.
<br>
<br>
Support Us on Patreon
<br>
<br>
Warm regards, The Freedium Team
</p>
<a href="https://noref.io/#https://patreon.com/Freedium" target=_blank title=Patreon>
    <button class="bg-red-400 mx-1 text-white hover:bg-red-500 font-semibold py-1 px-2 rounded mt-2">Patreon</button>
</a>
<button class="bg-gray-300 mx-1 hover:bg-gray-400 text-gray-800 font-semibold py-1 px-2 rounded mt-2 close-button">Close</button>
<a href="https://codeberg.org/Freedium-cfd/web" target=_blank title=Codeberg>
    <button class="bg-blue-800 hover:bg-blue-900 mx-1 text-white font-semibold py-1 px-2 rounded mt-2">Source code - Codeberg</button>
</a>
<a href="https://github.com/Freedium-cfd/web" target=_blank title=GitHub></a>
<button class="bg-gray-700 hover:bg-gray-600 mx-1 text-white font-semibold py-1 px-2 rounded mt-2">Source code - GitHub</button>

</div>
</div>
<nav id=header class="fixed w-full z-9 top-0 dark:bg-gray-800 dark:text-white bg-white shadow" style="z-index: 999990;">
    
    <div id=progress class="h-1 z-20 top-0" style="background:linear-gradient(to right, #4dc0b5 var(--scroll), transparent 0)"></div>
    <div class="w-full md:max-w-4xl mx-auto flex flex-wrap items-center justify-between mt-0 py-3">
        <div class=pl-4>
            <a class="text-green-500 text-base no-underline hover:no-underline font-extrabold text-xl" href="/" onclick=navigateToOrigin()>Freedium</a>
        </div>
        <div class="block lg:hidden pr-4">
            <button id=nav-toggle class="flex items-center px-3 py-2 border rounded text-gray-500 dark:text-white border-gray-600 hover:text-gray-900 dark:hover:text-white hover:border-green-500 appearance-none focus:outline-none">
                <svg class="fill-current h-3 w-3" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg">
                    <title>Menu</title>
                    <path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0v-2z"></path>
                </svg>
            </button>
        </div>
        <div class="w-full flex-grow lg:flex lg:items-center lg:w-auto hidden lg:block mt-2 lg:mt-0 dark:bg-gray-800 bg-white" id=nav-content>
            <ul class="list-reset lg:flex justify-end flex-1 items-center">
                <li class=mr-3>
                    <a class="inline-block text-gray-600 dark:text-white no-underline hover:text-gray-900 dark:hover:text-white hover:text-underline py-2 px-4" href="https://codeberg.org/Freedium-cfd/web" target=_blank>Source code</a>
                </li>
                <li class=mr-3>
                    <a class="inline-block text-gray-600 dark:text-white no-underline hover:text-gray-900 dark:hover:text-white hover:text-underline py-2 px-4" href="https://freedium-miror-saqg.vercel.app/" target=_blank>Mirror 1</a>
                </li>
                <li class=mr-3>
                    <a class="inline-block text-gray-600 dark:text-white no-underline hover:text-gray-900 dark:hover:text-white hover:text-underline py-2 px-4" href="https://freedium-mirror.vercel.app/" target=_blank>Mirror 2</a>
                </li>
                <li class=mr-3>
                    <a class="inline-block text-gray-600 dark:text-white no-underline hover:text-gray-900 dark:hover:text-white hover:text-underline py-2 px-4" href="https://romans-status-page.vercel.app/status/freedium" target=_blank>Status page</a>
                </li>
                <li class=mr-3>
                    <a class="inline-block text-gray-600 dark:text-white no-underline hover:text-gray-900 dark:hover:text-white hover:text-underline py-2 px-4" href="https://noref.io/#https://patreon.com/Freedium" target=_blank>Patreon - Support us</a>
                </li>
            </ul>
        </div>
    </div>
</nav>
<div class="container w-full md:max-w-3xl mx-auto pt-20 break-words text-gray-900 dark:text-gray-200 bg-white dark:bg-gray-800">
    <div class="w-full px-4 md:px-6 text-xl text-gray-800 dark:text-gray-100 leading-normal" style=font-family:Georgia,serif;>
        <div class=font-sans>
            <p class="text-base md:text-sm text-green-500 font-bold pb-3">
                <a href="https://medium.com/advanced-deep-learning/understanding-transformers-5291b0b75b2e#bypass" class="text-sm md:text-sm text-green-500 font-bold no-underline hover:underline ">&lt; Go to the original</a>
            </p>
            
                <img alt="Preview image" style="max-height: 65vh;
                            width: auto;
                            margin: auto" loading=eager role=presentation src="https://miro.medium.com/v2/resize:fit:700/1*flmmvFsoHKrcaVT48O7slA.png">
            
            <h1 class="font-bold font-sans break-normal text-gray-900 dark:text-gray-100 pt-6 pb-2 text-3xl md:text-4xl">Understanding Transformers</h1>
            <h2 class="font-medium font-sans break-normal text-gray-600 dark:text-gray-200 pt-1 text-1xl md:text-1xl">The underlying deep learning architecture for ChatGPT and new vision models.</h2>
        </div>
        <div class="bg-gray-100 dark:bg-gray-600 border border-gray-300 m-2 mt-5">
            <div class="flex items-center space-x-4 p-4">
                <div class=flex-shrink-0>
                    <a href="https://medium.com/@frederik.vl" target=_blank title="M.Sc. Artificial Intelligence &amp; M.Sc. Psychology. Interested in self-supervised learning, deep learning and deep brain decoding." class="block relative">
                        <img src="https://miro.medium.com/v2/resize:fill:88:88/1*J_y3cmDXpaRHy19lLO8_Pw.jpeg" alt="Frederik vom Lehn" class="rounded-full h-11 w-11 no-lightense">
                        <div class="absolute bottom-0 right-0 h-3 w-3 border-2 border-white bg-green-500 rounded-full"></div>
                    </a>
                </div>
                <div class=flex-grow>
                    <a href="https://medium.com/@frederik.vl" target=_blank title="M.Sc. Artificial Intelligence &amp; M.Sc. Psychology. Interested in self-supervised learning, deep learning and deep brain decoding." class="block font-semibold text-gray-900 dark:text-white">Frederik vom Lehn</a>
                    <button class="text-sm text-white bg-green-500 px-3 py-1 rounded-lg mt-1 dark:bg-green-700">
                        <a href="https://medium.com/@frederik.vl" target=_blank title="M.Sc. Artificial Intelligence &amp; M.Sc. Psychology. Interested in self-supervised learning, deep learning and deep brain decoding." class="block text-sm text-white">Follow</a>
                    </button>
                </div>
            </div>
            <div class="px-4 pb-2">
                <div class="flex flex-wrap items-center space-x-2 text-sm text-gray-500 dark:text-white">
                    
                        <a href="https://medium.com/advanced-deep-learning" title="Deep learning is a subset of machine learning focused onâ€¦" target=_blank class="flex items-center space-x-1">
                            <img src="https://miro.medium.com/v2/resize:fill:48:48/1*yIXaGSW_MaLiYvH-NFOISg.png" alt="Advanced Deep Learning" class="h-4 w-4 rounded-full no-lightense">
                            <p>Advanced Deep Learning</p>
                        </a>
                        <span>Â·</span>
                    
                    <span class="text-gray-500 dark:text-white">~6 min read</span>
                    <span class=md:inline>Â·</span>
                    <span class="text-gray-500 dark:text-white">May 29, 2024 (Updated: May 29, 2024)</span>
                    <span class=md:inline>Â·</span>
                    <span class="text-yellow-500 dark:text-yellow-400">Free: No</span>
                </div>
            </div>
        </div>
        <div class="main-content mt-8">
            <p class="leading-8 mt-7">This article has a deep focus on visualising some aspect of a transformer. We start with the preperation of input data. In most cases, this is plane text. However, one can also use images or timeseries data such as EEG.<div class=mt-7><img alt=None style="margin: auto;" class="pt-5 lazy" role=presentation data-src="https://miro.medium.com/v2/resize:fit:700/1*PZCpIVtG7nRdyAhjrin_ig.png"></div><figcaption class="mt-3 text-sm text-center text-gray-500 dark:text-gray-200">Input to transformers: Tokenisation [Image by Author.]</figcaption><p class="leading-8 mt-7">When we use transformers with text, we first use a tokeniser to map each word into integers. Some tokeniser even subdivide words, this process can be seen on the illustration above. Common Tokenisers are for example:<p class="leading-8 mt-7">Google: SentencePiece Github: <a class=text-base style="text-decoration: underline;" rel="" title="" href="https://github.com/google/sentencepiece" target=_blank>https://github.com/google/sentencepiece</a><p class="leading-8 mt-7">OpenAI: Tiktoken Github: <a class=text-base style="text-decoration: underline;" rel="" title="" href="https://github.com/openai/tiktoken" target=_blank>https://github.com/openai/tiktoken</a><p class="leading-8 mt-7">After tokenisation, we map each token to an word embedding. A word embedding is just a vector in a vector space. This is crucial because it allows us to store meaningful information about every input word/token. For instance, if the word is related to gender, or might represent affection or is a heavy object. The image below illustrates this exmaple. However, those word embeddings only store general information about the word and cannot take current context into account.<div class=mt-7><img alt=None style="margin: auto;" class="pt-5 lazy" role=presentation data-src="https://miro.medium.com/v2/resize:fit:700/1*m0RxmbkSY-td4Q-xwmqUHw.png"></div><figcaption class="mt-3 text-sm text-center text-gray-500 dark:text-gray-200">Feature Dimensions and the Embedding Space [Image by Author.]</figcaption><h4 class="font-bold font-sans break-normal text-gray-900 dark:text-gray-100 text-l md:text-xl pt-8">The main goal of a transformer</h4><p class="leading-8 mt-3">The main objective of a transformer is to learn the relationships between each element in the input data and produce a represention for each input element that learned its meaning based on the context. For exmaple, that the word bank is a financial institute in the sentence "I have to change my bank, they charge too much interest". In contrast, the same word bank has a different meaning in the sentence "I really like how comfortable my bank is".<p class="leading-8 mt-7">As discussed before, the input to transformers are embeddings, in the case of words, they already have some information about the word. However, they don't have any contextual awareness. The picture below illustrates this. In this case, the transformer changed the word embedding of the input word "bank" so that is got closer to the word "Chair" in the embedding space. If we now work with this embedding, due to the embedding space, the model now knows that the word "bank" is related to the concept of a piece of furniture for the current task. This means, if we want to generate some new words, it is more likely that words related to the concept "living", "chair", "table", etc., are shown than "finance", "money", etc.<div class=mt-7><img alt=None style="margin: auto;" class="pt-5 lazy" role=presentation data-src="https://miro.medium.com/v2/resize:fit:700/1*8hTFppg48XWsSBJ2swO2kA.png"></div><figcaption class="mt-3 text-sm text-center text-gray-500 dark:text-gray-200">The output is a learned <em>context-dependent </em>representation of the input [Image by Author.]</figcaption><h4 class="font-bold font-sans break-normal text-gray-900 dark:text-gray-100 text-l md:text-xl pt-8">Transformer Input, Output and Use cases</h4><p class="leading-8 mt-3">Sometimes it is hard to understand how we can use transformers and what exactly is the output. In the illustration below, I visualised two different potential use cases: (1) Sentiment classification and (2) next word generation.<div class=mt-7><img alt=None style="margin: auto;" class="pt-5 lazy" role=presentation data-src="https://miro.medium.com/v2/resize:fit:700/1*TwZ2ChGkAgOKI9dF9_U2XA.png"></div><figcaption class="mt-3 text-sm text-center text-gray-500 dark:text-gray-200">Transformers can be used for auto-regressive word generation or sentiment classification tasks [Image by Author.]</figcaption><p class="leading-8 mt-7">We see that we first convert an input sentence "Nice weather outside" into tokens, which are just integers. Those tokens are then mapped to word embeddings. Those word embeddings can be learned or initialised through Embedding models such as Word2vec or Glove. Now they store some information about each word, but no context information.<p class="leading-8 mt-7">We add a positional embedding to each word embedding. This results into our input matrix of dimension NxD. Where N is the number of input words and D the size of the Dimension for each word embedding.<p class="leading-8 mt-7">We pass this into a transformer block and the output is a matrix with the same dimension NxD. However, each word embedding is now changed to also store context information.<p class="leading-8 mt-7">We can now use the last embedding of the last word only, because it also has the information of all other word embeddings. We can simply pass it into an logistic regression to do sentiment analyses, which might classify if the input sentence is negative, positive or neutral. But we can also generate a new word based on the input sentence. For that we map the last word embedding of Dimension 1xD with a fully connected layer to all possible words V. We apply Softmax to get the probability distribution of which word should be next.<h4 class="font-bold font-sans break-normal text-gray-900 dark:text-gray-100 text-l md:text-xl pt-8">Transformer Block</h4><p class="leading-8 mt-3">The illustration below shows how a typical transformer block works. We have different components.<p class="leading-8 mt-7"><strong>Attention Head: </strong>First, different self-attention heads are applied to the input matrix in order to learn the relationship between each input element. Each multihead self-attention layer has its own set of key, query, and value weight matrices. The outputs from each head are concatenated and then passed into the normalisation layer. Each attention head might learn another concept of relationships between the input data.<p class="leading-8 mt-7"><strong>Normalisation: </strong>The normalisation layer is basically just the Z-Score, where the vector values are normalized by subtracting the mean from each and dividing by the standard deviation. That centres the data around a zero mean, with a standard deviation of one.<div class=mt-7><img alt=None style="margin: auto;" class="pt-5 lazy" role=presentation data-src="https://miro.medium.com/v2/resize:fit:700/1*9nvPIHY9QFa9pzulw5wViw.png"></div><figcaption class="mt-3 text-sm text-center text-gray-500 dark:text-gray-200">Transformer Block [Image by Author.]</figcaption><p class="leading-8 mt-7"><strong>Feed Forward: </strong>Each word vector is passed through the same feedforward network independently and in parallel. It does not mix information between different words within the sequence. It introduces Non-Linearity and enhances the model capacity to learn. The FFN helps to create individual context mappings.<p class="leading-8 mt-7"><strong>SkipConnections: </strong>This allows the network to represent all the functions it was able to represent before the layer, plus the newly acquired representational power from this current layer.<h4 class="font-bold font-sans break-normal text-gray-900 dark:text-gray-100 text-l md:text-xl pt-8">Understand the attention head</h4><div class=mt-7><img alt=None style="margin: auto;" class="pt-5 lazy" role=presentation data-src="https://miro.medium.com/v2/resize:fit:700/1*flmmvFsoHKrcaVT48O7slA.png"></div><figcaption class="mt-3 text-sm text-center text-gray-500 dark:text-gray-200">Transformers Attention Head [Image by Author.]</figcaption><p class="leading-8 mt-7">The goal is to get a representation of each input word/token that takes all other input tokens into account. For that a transformer transforms the input into a new representation. This is done by using three weight matrices called Query, Key and Value. So for each word we get three transformations. The same word is depicted as query vector, key vector and value vector. The idea is to compare each word represented as query vector with all other words represented as key vectors. Remember, it is not the word embedding it self that is beeing compared to all other word embeddings. Instead, it is a transformed representation of the word embedding, that is based on learned weights. So this new represention might contain slightly different information about the word compared to the initial word embedding, which already captures information about the word. The comparison of the transformed words is simply the dot product, which measure the similarity between each vector. The similarity scores are then downscaled and normalised with softmax. The result is an attention matrix which depicts how similar each word representation is with respect to all other words.<p class="leading-8 mt-7"><strong>Why downscaling?</strong> The result of a dot product can vary widely, producing very large positive or negative values. Exponentiating these large values can cause numerical issues and lead to a loss of gradients during training. To prevent this, we scale down the dot product result by dividing it by a factor related to the size of the embeddings.<p class="leading-8 mt-7">We put all values to -inf in the upper triangle to avoid comparison of future words that has not been processed in the sequence yet. This is not the case in bi-directional self attention-heads.<p class="leading-8 mt-7">As mentioned earlier, the output of the attention head is a matrix of shape <em>N</em>Ã—D. The Embedding for each word now captures the relationship to all other words.</p>
        </div>
        <div class="flex flex-wrap gap-2 mt-5">
            <a title=Transformers target=_blank href="https://medium.com/tag/transformers"><span class="text-green-500 bg-green-100 px-2 py-1 rounded-full text-xs dark:bg-green-800 dark:text-gray-100">#transformers</span></a><a title="Machine Learning" target=_blank href="https://medium.com/tag/machine-learning"><span class="text-green-500 bg-green-100 px-2 py-1 rounded-full text-xs dark:bg-green-800 dark:text-gray-100">#machine-learning</span></a><a title="Language Model" target=_blank href="https://medium.com/tag/language-model"><span class="text-green-500 bg-green-100 px-2 py-1 rounded-full text-xs dark:bg-green-800 dark:text-gray-100">#language-model</span></a><a title=Attention target=_blank href="https://medium.com/tag/attention"><span class="text-green-500 bg-green-100 px-2 py-1 rounded-full text-xs dark:bg-green-800 dark:text-gray-100">#attention</span></a><a title=Explained target=_blank href="https://medium.com/tag/explained"><span class="text-green-500 bg-green-100 px-2 py-1 rounded-full text-xs dark:bg-green-800 dark:text-gray-100">#explained</span></a>
        </div>
        <div class="container w-full md:max-w-3xl mx-auto pt-12"></div>
    </div>
    <style>
.main-content {
 letter-spacing: -0.06px;
 font-family: source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif;
}
code {
    background-color: #e3e2e2;
}
pre {
    font-size: 75%;
    background-color: #e3e2e2;
}
p code, ul code, li code {
    font-size: 75%;
}
    </style>
    <script>
document.addEventListener('DOMContentLoaded', (event) => {
  hljs.highlightAll();

  document.querySelectorAll('pre code').forEach((el) => {
         code = el.textContent;  
          el = el.parentElement;
         el.innerHTML = '<button class="hljs-copy p-1 bg-gray-300 dark:bg-black">Copy</button>' + el.innerHTML; // append copy button
        el.getElementsByClassName('hljs-copy')[0].contentCopy = code;
         el.getElementsByClassName('hljs-copy')[0].addEventListener("click", function () {
             this.innerText = 'Copying..';
             if (!navigator.userAgent.toLowerCase().includes('safari')) {
                 navigator.clipboard.writeText(this.contentCopy);
             } else {
                 prompt("Clipboard (Select: âŒ˜+a > Copy:âŒ˜+c)", this.contentCopy);
             }
             this.innerText = 'Copied!';
             button = this;
             setTimeout(function () {
                 button.innerText = 'Copy';
             }, 1500)
         });
});
  });
    </script>
    <style>
     .hljs-copy {
         float: right;
         cursor: pointer;
     }
    </style>
<div id=problemModal class="modal hidden fixed inset-0 w-full h-full flex items-center justify-center overflow-y-auto bg-black bg-opacity-50" style="z-index: 999999">
    <div class="modal-container w-11/12 md:max-w-xl mx-auto rounded shadow-lg max-h-screen">
        <div class="modal-content bg-white dark:bg-gray-800 dark:text-white my-8 py-4 text-left px-6">
            <h1 class="text-3xl font-bold">Reporting a Problem</h1>
            <div class=mt-3>
                <p>
                    Sometimes we have problems displaying some Medium posts.
                <br>
            <br>
        </p>
        <p>If you have a problem that some images aren't loading - try using VPN. Probably you have problem with access to Medium CDN (or fucking Cloudflare's bot detection algorithms are blocking you).</p>
    </div>
    <form action=# method=POST class=mt-4 id=problem-form>
        <div class=mb-4>
            <label for=problem-description class="block text-gray-700 dark:text-white font-bold mb-2">Problem Description</label>
            <textarea id=problem-description name=problem-description placeholder="Describe your problem here..." class="shadow appearance-none border rounded w-full py-2 px-3 text-gray-700 leading-tight focus:outline-none focus:shadow-outline" rows=4 required=""></textarea>
        </div>
        <div>
            <button type=submit class="m-2 bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded focus:outline-none focus:shadow-outline">Submit</button>
            <button type=button class="m-2 modal-close bg-gray-500 hover:bg-gray-700 text-white font-bold py-2 px-4 rounded focus:outline-none focus:shadow-outline">Cancel</button>
        </div>
    </form>
</div>
</div>
</div>
<script>
    tailwind.config = {
        darkMode: 'class',
    }

  function navigateToOrigin() {
    window.location.href = window.location.origin;
  }
if (localStorage.theme === 'dark' || (!('theme' in localStorage) && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
  // document.documentElement.classList.add('dark');
  document.getElementById('darkIcon').classList.remove('hidden');
  document.getElementById('lightIcon').classList.add('hidden')
} else {
  // document.documentElement.classList.remove('dark')
  document.getElementById('lightIcon').classList.remove('hidden');
  document.getElementById('darkIcon').classList.add('hidden');
}

  document.getElementById('darkModeToggle').addEventListener('click', function() {

    if (localStorage.theme === 'dark' || (!('theme' in localStorage) && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
  document.documentElement.classList.remove('dark');
  document.getElementById('darkIcon').classList.add('hidden');
  document.getElementById('lightIcon').classList.remove('hidden')
  document.documentElement.style.cssText = "--lightense-backdrop: white;";
  localStorage.setItem("theme", "light")
} else {
  document.documentElement.classList.add('dark')
  document.getElementById('lightIcon').classList.add('hidden');
  document.getElementById('darkIcon').classList.remove('hidden');
  document.documentElement.style.cssText = "--lightense-backdrop: black;";
  localStorage.setItem("theme", "dark")
}
});
</script>
<script>
                const openModalButton = document.getElementById('openProblemModal');
                const closeModalButton = document.querySelector('.modal-close');
                const modal = document.getElementById('problemModal');
                const problemDescriptionInput = document.getElementById('problem-description');
                const submitButton = document.querySelector('form button');
                const body = document.querySelector('body');

                openModalButton.addEventListener('click', () => {
                    body.classList.add('overflow-hidden'); // Prevent scrolling on the body
            modal.classList.remove('hidden');
        });

        closeModalButton.addEventListener('click', () => {
            body.classList.remove('overflow-hidden'); // Re-enable scrolling on the body
            modal.classList.add('hidden');
        });

        modal.addEventListener('click', (e) => {
            if (e.target === modal) {
                modal.classList.add('hidden');
                body.classList.remove('overflow-hidden');
            }
        });

        function navigateNoCache() {
                window.location.href = `/render-no-cache${window.location.pathname}`;
        }

        const submitForm = async (event) => {
            event.preventDefault();

            console.log('Form submiting is started!');
            submitButton.disabled = true;

            // Get the problem description from the input field
            const problemDescription = problemDescriptionInput.value;
            const currentPage = window.location.href;

            try {
                // Send a POST request to the "report-problem" API endpoint
                const response = await fetch('/report-problem', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ description: problemDescription, page: currentPage }),
                });

                if (response.ok) {
                    // Report submitted successfully, you can add a success message or further actions here
                    console.log('Problem report submitted successfully.');
                    modal.classList.add('hidden'); // Close the modal
                } else {
                    // Handle errors, such as non-200 responses
                    console.error('Failed to submit problem report.');
                    submitButton.disabled = false;
                }
            } catch (error) {
                // Handle network errors or other exceptions
                console.error('An error occurred:', error);
                submitButton.disabled = false;
            }
        };

        document.getElementById('problem-form').onsubmit = submitForm;
</script>
<script>
const h = document.documentElement, b = document.body;
const st = 'scrollTop';
const sh = 'scrollHeight';
const progress = document.getElementById('progress');
const header = document.getElementById('header');
const navcontent = document.getElementById('nav-content');

document.addEventListener('scroll', function () {
  /* Refresh scroll % width */
  const scroll = (h[st] || b[st]) / ((h[sh] || b[sh]) - h.clientHeight) * 100;
  progress.style.setProperty('--scroll', scroll + '%');

  /* Apply classes for slide in bar */
  const shouldAddClass = window.scrollY > 10;
});

		document.getElementById('nav-toggle').onclick = function() {
			document.getElementById("nav-content").classList.toggle("hidden");
		}

  window.addEventListener('load', function () {
       Lightense('img:not(.no-lightense)');
  }, false);
</script>


<script>
            var lazyLoadInstance = new LazyLoad({
                    callback_loaded: function(element) {
        Lightense(element);
    },
    callback_error: (img) => {
        console.log(img);
        if (img.hasAttribute("data-src")) {
            if (img.attributes["data-src"].value.startsWith("https://miro.medium.com/v2/")) {
            img.setAttribute("src", img.attributes["data-src"].value.replace("https://miro.medium.com/v2/", "https://freedium.cfd/@miro/v2/" ));
            }
        }
  }
});
</script>
<script>
    function navigateToOrigin() {
      window.location.href = window.location.origin;
    }
</script>
<script>
      document.addEventListener('DOMContentLoaded', () => {
        const notificationContainer = document.querySelector('.notification-container');
        const closeButton = document.querySelector('.close-button');
        const notificationFlagString = "showNotification-buymeacoffe-ban-block"
        const body = document.querySelector('body');

        function showNotification() {
          if (!localStorage.getItem(notificationFlagString)) {
                  notificationContainer.style.display = 'block';
                  body.classList.add('overflow-hidden');
          }
        }

        function hideNotification() {
          localStorage.setItem(notificationFlagString, 'false');
          notificationContainer.style.display = 'none';
          body.classList.remove('overflow-hidden');
        }

        // Close button functionality
        closeButton.addEventListener('click', () => {
          hideNotification();
        });

        showNotification();
      });
</script></div>